{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import CIFAR10\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import ArcFaceModel\n",
    "from visualization import visualize_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create an instance of ArcFaceModel\n",
    "model = ArcFaceModel(num_classes=10, embedding_size=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"models/best_model.pth\"\n",
    "\n",
    "#load the model weights\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Load cifa10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "dataset = CIFAR10(root='data/cifar10', download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample some examples belonging to class 1 and 2\n",
    "# dataset.targets is a list, so need to first convert it to a tensor\n",
    "class1 = dataset.data[np.array(dataset.targets) == 1][:10]\n",
    "\n",
    "class2 = dataset.data[np.array(dataset.targets) == 2][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embedding of class 1 and 2\n",
    "embeddings1 = model.get_embedding(torch.tensor(class1).permute(0,3,1,2).float().to(device))\n",
    "embeddings2 = model.get_embedding(torch.tensor(class2).permute(0,3,1,2).float().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#Cosine similarity between embeddings of class 1 and 2\n",
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "print(cos(embeddings1, embeddings2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read celeba annotations\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the annotations file\n",
    "df = pd.read_csv(\"data/identity_CelebA.txt\", sep=\" \", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.jpg</td>\n",
       "      <td>2880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002.jpg</td>\n",
       "      <td>2937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000003.jpg</td>\n",
       "      <td>8692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000004.jpg</td>\n",
       "      <td>5805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000005.jpg</td>\n",
       "      <td>9295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0     1\n",
       "0  000001.jpg  2880\n",
       "1  000002.jpg  2937\n",
       "2  000003.jpg  8692\n",
       "3  000004.jpg  5805\n",
       "4  000005.jpg  9295"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1\n",
       "3227    35\n",
       "2820    35\n",
       "3782    35\n",
       "3745    34\n",
       "3699    34\n",
       "        ..\n",
       "8815     1\n",
       "9770     1\n",
       "2264     1\n",
       "9075     1\n",
       "3481     1\n",
       "Name: count, Length: 10177, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of images for each identity sorted descending\n",
    "\n",
    "df[1].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The images are saved in the img_align_celeba folder\n",
    "\n",
    "# Load images and labels and put them in a torch dataset\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "\n",
    "class CelebADataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, annotations_file, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.annotations = pd.read_csv(annotations_file, sep=\" \", header=None)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
    "        image = Image.open(img_path)\n",
    "        label = torch.tensor(self.annotations.iloc[index, 1])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return (image, label)\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop(178),\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "    ])\n",
    "\n",
    "    \n",
    "# Create an instance of the dataset\n",
    "dataset = CelebADataset(root_dir=\"data/img_align_celeba\", annotations_file=\"data/identity_CelebA.txt\", transform=transform)\n",
    "\n",
    "#Take only four identities with the most images\n",
    "dataset = Subset(dataset, np.where(np.array(dataset.annotations[1].value_counts().sort_values(ascending=False)[:4]))[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
